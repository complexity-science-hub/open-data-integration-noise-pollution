{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas_profiling\n",
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from analysis.settings.settings import DevelopmentConfig\n",
    "c = DevelopmentConfig\n",
    "\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open data integration\n",
    "Cleaning shape files delivered as open data from http://www.laerminfo.at/laermkarten/methoden/inspire.html\n",
    "\n",
    "> an accompanying blog post can be found at: https://georgheiler.com/2019/02/08/noise-pollution-data-cleanup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_dirs(directory_in_str, glob):\n",
    "    pathlist = Path(directory_in_str).glob(glob)\n",
    "    for path in pathlist:\n",
    "        yield str(path)\n",
    "        \n",
    "def parse_attributes_from_path(path):\n",
    "    file_name = path.split('/')[-1]\n",
    "    elements = file_name.split('_')\n",
    "    result = {}\n",
    "    result['year'] = elements[0]\n",
    "    result['kind'] = elements[1]\n",
    "    result['timing'] = elements[2]\n",
    "    result['state'] = elements[-1].split('.')[0]\n",
    "    return result\n",
    "\n",
    "def add_columns_to_df(df, items):\n",
    "    for key, value in items.items():\n",
    "        df[key] = value\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = iter_dirs(c.BASE_PATH, '**/*.shp')\n",
    "#items = 2\n",
    "#print(f\"WARN UNSET THIS FOR PRODUCTION. currently only {items} are processed\")\n",
    "#paths = itertools.islice(paths, items)\n",
    "tmp_appended_data = []\n",
    "for path in tqdm(paths):\n",
    "    attributes_from_filenname = parse_attributes_from_path(path)\n",
    "    df = gp.read_file(path)\n",
    "    df = add_columns_to_df(df, attributes_from_filenname)\n",
    "    tmp_appended_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(tmp_appended_data, axis=0, sort=False)\n",
    "df = df.reset_index(drop=True)\n",
    "display(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.crs = {'init' :'epsg:31287'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output files\n",
    "Geopackage is a nice standard and a bit more structured than CSV. But CSV is more versatile i.e. as no spatial index and type information are present polygon and multipolygons can be put into the same column. That's why we need to convert geometries to the same type as outlined below.\n",
    "\n",
    "### CSV\n",
    "is a bit smaller in file size and has no spatial index / less optimal compared to gpkg but more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(c.BASE_PATH + 'noise_pollution.gzip.csv', index=False, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parquet\n",
    "A further option is to store as parquet files. They do not support a binary geometry. But can easily be loaded to parall programs like spark.\n",
    "\n",
    "> NOTE this time also a reprojection to WGS84 is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geometry'] = df['geometry'].apply(lambda g: g.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(c.BASE_PATH + 'noise_pollution.parquet', compression='gzip', partition_cols=['kind', 'state', 'timing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPKG\n",
    "\n",
    "The cooridnate system is `EPSG:31287`, http://spatialreference.org/ref/epsg/mgi-austria-lambert-2/ it can be stored in the geodatabase for easier downstream processing.\n",
    "\n",
    "Convert to all multipolygon shapes to support a single type of geometry in gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def convert_polygon_to_multipolygon(raw_geometry):\n",
    "    if(isinstance(raw_geometry, shapely.geometry.polygon.Polygon)):\n",
    "        return MultiPolygon([raw_geometry])\n",
    "    else:\n",
    "        # we currently only have MULTIPOLYGON and POLYGON so plain else is good enough\n",
    "        return raw_geometry\n",
    "            \n",
    "df.geometry = df.geometry.apply(convert_polygon_to_multipolygon)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_file(c.BASE_PATH + 'noise_pollution.gpkg', driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
